f1 = 10, f2 = 3, f3 = 1, f4 = 2,
p1 = 0, p2 = 0, p3 = pi/2, p4 = 0) {
data.frame(t = seq(0, 350*pi, 350*pi/n)) %>%
dplyr::mutate(
x = runif(1, A1,1)*sin(t*f1+p1)*exp(-d1*t) + A2*sin(t*f2+p2)*exp(-d2*t),
y = runif(1, A3,1)*sin(t*f3+p3)*exp(-d3*t) + A4*sin(t*f4+p4)*exp(-d4*t)
) %>%
dplyr::select(-t)
}
x11()
harmonograph() %>%
ggplot(aes(x,y)) +
geom_point(alpha = .03, size = .03)
harmonograph <- function(n = 500000,
A1 = 5, A2 = 6, A3 = 7, A4 = 1,
d1 = 0.039, d2 = 0.006, d3 = 0, d4 = 0.0045,
f1 = 10, f2 = 3, f3 = 1, f4 = 2,
p1 = 0, p2 = 0, p3 = pi/2, p4 = 0) {
data.frame(t = seq(0, 350*pi, 350*pi/n)) %>%
dplyr::mutate(
x = A1*sin(t*f1+p1)*exp(-d1*t) + A3*sin(t*f2+p2)*exp(-d2*t),
y = A2*sin(t*f3+p3)*exp(-d3*t) + A4*sin(t*f4+p4)*exp(-d4*t)
) %>%
dplyr::select(-t)
}
x11()
harmonograph() %>%
ggplot(aes(x,y)) +
geom_point(alpha = .03, size = .03)
harmonograph <- function(n = 500000,
A1 = 1, A2 = 6, A3 = 7, A4 = 1,
d1 = 0.039, d2 = 0.006, d3 = 0, d4 = 0.0045,
f1 = 10, f2 = 3, f3 = 1, f4 = 2,
p1 = 0, p2 = 0, p3 = pi/2, p4 = 0) {
data.frame(t = seq(0, 350*pi, 350*pi/n)) %>%
dplyr::mutate(
x = A1*sin(t*f1+p1)*exp(-d1*t) + A3*sin(t*f2+p2)*exp(-d2*t),
y = A2*sin(t*f3+p3)*exp(-d3*t) + A4*sin(t*f4+p4)*exp(-d4*t)
) %>%
dplyr::select(-t)
}
x11()
harmonograph() %>%
ggplot(aes(x,y)) +
geom_point(alpha = .03, size = .03)
cool_shape = c(A1 = 1, A2 = 1, A3 = 1, A4 = 1,
d1 = 0.0085, d2 = 0, d3 = 0.065, d4 = 0,
f1 = 2.01, f2 = 3, f3 = 3, f4 = 2,
p1 = 0, p2 = 7*pi/16, p3 = 0, p4 = 0)
cool_shape
harmonograph(cool_shape) %>%
ggplot(aes(x,y)) +
geom_point(alpha = .03, size = .03)
harmonograph(A1 = 1, A2 = 1, A3 = 1, A4 = 1,
d1 = 0.0085, d2 = 0, d3 = 0.065, d4 = 0,
f1 = 2.01, f2 = 3, f3 = 3, f4 = 2,
p1 = 0, p2 = 7*pi/16, p3 = 0, p4 = 0) %>%
ggplot(aes(x,y)) +
geom_point(alpha = .03, size = .03)
x11()
cool_shape = c(A1 = 1, A2 = 1, A3 = 1, A4 = 1,
d1 = 0.0085, d2 = 0, d3 = 0.065, d4 = 0,
f1 = 2.01, f2 = 3, f3 = 3, f4 = 2,
p1 = 0, p2 = 7*pi/16, p3 = 0, p4 = 0)
harmonograph(A1 = 1, A2 = 1, A3 = 1, A4 = 1,
d1 = 0.0085, d2 = 0, d3 = 0.065, d4 = 0,
f1 = 2.01, f2 = 3, f3 = 3, f4 = 2,
p1 = 0, p2 = 7*pi/16, p3 = 0, p4 = 0) %>%
ggplot(aes(x,y)) +
geom_point(alpha = .03, size = .03)
install.packages("mathart")
x11()
# have to copy and paste this in to get a cool shape
# The A parameters seem to exagerate the shape you get in some ways
# A1 = 1, A2 = 1, A3 = 1, A4 = 1,
# d1 = 0.0085, d2 = 0, d3 = 0.065, d4 = 0,
# f1 = 2.01, f2 = 3, f3 = 3, f4 = 2,
# p1 = 0, p2 = 7*pi/16, p3 = 0, p4 = 0
harmonograph(A1 = 1, A2 = 1, A3 = 1, A4 = 1,
d1 = 0.0085, d2 = 0, d3 = 0.065, d4 = 0,
f1 = 2.01, f2 = 3, f3 = 3, f4 = 2,
p1 = 0, p2 = 7*pi/16, p3 = 0, p4 = 0) %>%
ggplot(aes(x,y)) +
geom_path(aes(x, y), df, alpha = 0.25, size = 0.5) +
coord_equal()
harmonograph(A1 = 1, A2 = 1, A3 = 1, A4 = 1,
d1 = 0.0085, d2 = 0, d3 = 0.065, d4 = 0,
f1 = 2.01, f2 = 3, f3 = 3, f4 = 2,
p1 = 0, p2 = 7*pi/16, p3 = 0, p4 = 0) %>%
ggplot(aes(x,y)) +
geom_path(aes(x, y), alpha = 0.25, size = 0.5) +
coord_equal()
R.version()
R.version
dir()
d <- read.csv("lilkelsey.csv")
head(d)
colnames(d) <- c("date", "followers", "Posty")
head(d)
library(tidyverse)
d %>%
ggplot(aes(data, colour = Posty, fill = Posty)) +
geom_point()
d %>%
ggplot(aes(data, colour = Posty, fill = Posty)) +
geom_bar()
d %>%
ggplot(aes(date, followers, colour = Posty, fill = Posty)) +
geom_bar()
d %>%
ggplot(aes(date, followers, colour = Posty, fill = Posty)) +
geom_point()()
d %>%
ggplot(aes(date, followers, colour = Posty, fill = Posty)) +
geom_point()
d %>%
ggplot(aes(date, followers, colour = Posty, fill = Posty)) +
geom_col()
d %>%
ggplot(aes(date, followers, colour = Posty, fill = Posty)) +
geom_col() + theme_bw() + see::scale_color_flat() + see::scale_fill_flat()
n_participants_2 = 30
# how many people do we expect to be able to do the second part
attrition = 1
# how many people would we need to test to get the desired n for
# part 2 given some attrition rate
n_participants_1 = ceiling(n_participants_2/attrition)
# both parts in one with two lots of participants doing two different tasks that should be matched in terms of time
n_participants = 30
n_conditions = 2
time = 20
Cost = (prolific_cpm * time * n_participants) + (n_participants * prolific_cpp) + (n_participants + pavlovia_cpp)
Cost
n_participants_1 = ceiling(n_participants_2/attrition)
# Session times
Session_1 = 10
# this is a guess at the moment
# Depends on how we want to set up part 2
Session_2 = 15
# Cost
# cost per minute
prolific_cpm = 0.125
# cost per participant
prolific_cpp = .5
pavlovia_cpp = .2
# total cost
Cost_session1 = (prolific_cpm * Session_1 * n_participants_1) + (n_participants_1 * prolific_cpp) + (n_participants_1 * pavlovia_cpp)
Cost_session2 = (prolific_cpm * Session_2 * n_participants_2) + (n_participants_2 * prolific_cpp) + (n_participants_2 * pavlovia_cpp)
Cost = Cost_session1 + Cost_session2
Cost
#### new setup ####
# both parts in one with two lots of participants doing two different tasks that should be matched in terms of time
n_participants = 30
n_conditions = 2
time = 20
Cost = (prolific_cpm * time * n_participants) + (n_participants * prolific_cpp) + (n_participants + pavlovia_cpp)
Cost
Cost = (prolific_cpm * time * n_participants) + (n_participants * prolific_cpp) + (n_participants + pavlovia_cpp) * n_conditions
Cost
Cost = ((prolific_cpm * time * n_participants) + (n_participants * prolific_cpp) + (n_participants + pavlovia_cpp)) * n_conditions
Cost
d %>%
ggplot(aes(followers, colour = Posty, fill = Posty)) +
geom_histogram() + theme_bw() + see::scale_color_flat() + see::scale_fill_flat()
d %>%
ggplot(aes(followers, colour = Posty, fill = Posty)) +
geom_histogram(position = "dodge") + theme_bw() + see::scale_color_flat() + see::scale_fill_flat()
d %>%
mutate(prev_day_post = lag(Posty, 1))
d %>%
mutate(prev_day_post = lag(Posty, 1)) %>%
drop_na() %>%
ggplot(aes(followers, fill = prev_day_post)) +
geom_histogram(position = "dodge")
d %>%
mutate(prev_day_post = lag(Posty, 1)) %>%
drop_na() %>%
mutate(cat = paste(Posty, prev_day_post, sep = "_")) %>%
ggplot(aes(followers, fill = cat)) +
geom_histogram(position = "dodge")
# how many participants do we want
n_participants_2 = 30
# how many people do we expect to be able to do the second part
attrition = .8
# how many people would we need to test to get the desired n for
# part 2 given some attrition rate
n_participants_1 = ceiling(n_participants_2/attrition)
# Session times
Session_1 = 10
# this is a guess at the moment
# Depends on how we want to set up part 2
Session_2 = 15
# Cost
# cost per minute
prolific_cpm = 0.125
# cost per participant
prolific_cpp = .5
pavlovia_cpp = .2
# total cost
Cost_session1 = (prolific_cpm * Session_1 * n_participants_1) + (n_participants_1 * prolific_cpp) + (n_participants_1 * pavlovia_cpp)
Cost_session2 = (prolific_cpm * Session_2 * n_participants_2) + (n_participants_2 * prolific_cpp) + (n_participants_2 * pavlovia_cpp)
Cost = Cost_session1 + Cost_session2
Cost
#### new setup ####
# both parts in one with two lots of participants doing two different tasks that should be matched in terms of time
n_participants = 30
n_conditions = 2
time = 20
Cost = ((prolific_cpm * time * n_participants) + (n_participants * prolific_cpp) + (n_participants + pavlovia_cpp)) * n_conditions
Cost
prolific_cpm * time
library(tidyverse)
m <- 3
sd <- .2
iter <- 10000
tibble(value = rnorm(iter, m, sd)) %>%
ggplot(aes(exp(value))) +
geom_density()
# plinko machine
df_plink <- tibble(drop = numeric(),
time = numeric(),
direction = numeric(),
x_pos = numeric())
steps = 51
iters = 10000
n = steps * iters
df_plink <- data.table::data.table(drop = rep(0,n),
time = rep(0,n),
direction = rep(0,n),
x_pos = rep(0,n))
count = 0
steps = 10
iters = 10000
sqrt(10)
count = 0
for(ii in 1:iters){
init_x = 0
x = init_x
for(t in 0:(steps-1)){
count = count + 1
if(t > 0){
move = runif(1, 0, 1)
if(move <= .5){
move = -1
} else {
move = 1
}
x = x + move
}
# add in data frame
df_plink[count, drop := ii]
df_plink[count, time := t]
df_plink[count, direction := move]
df_plink[count, x_pos := x]
}
}
move = runif(1, 0, 1)
move
steps = 10
iters = 10000
n = steps * iters
df_plink <- data.table::data.table(drop = rep(0,n),
time = rep(0,n),
direction = rep(0,n),
x_pos = rep(0,n))
count = 0
for(ii in 1:iters){
init_x = 0
x = init_x
for(t in 0:(steps-1)){
count = count + 1
if(t > 0){
move = runif(1, 0, 1)
if(move <= .5){
move = -1
} else {
move = 1
}
x = x + move
}
# add in data frame
df_plink[count, drop := ii]
df_plink[count, time := t]
df_plink[count, direction := move]
df_plink[count, x_pos := x]
}
}
# plot this
df_plink %>%
mutate(time = (time * -1) + max(time)) %>%
# filter(time < 5) %>%
ggplot(aes(time, x_pos)) +
geom_line(aes(group = drop),
alpha = .1) +
coord_flip() +
theme_bw()
x11()
df_plink %>%
mutate(time = (time * -1) + max(time)) %>%
# filter(time < 5) %>%
ggplot(aes(time, x_pos)) +
geom_line(aes(group = drop),
alpha = .1) +
coord_flip() +
theme_bw()
df_plink %>%
mutate(dist = abs(x_pos)) %>%
ggplot(aes(dist)) +
geom_density()
df_plink %>%
mutate(dist = abs(x_pos)) %>%
summarise(mu = mean(dist),
med = median(dist))
sqrt(10)
df_plink %>%
mutate(dist = abs(x_pos)) %>%
summarise(mu = mean(dist)*2,
med = median(dist))
dir()
22.7
22/7
#### Modelling ####
# Modelling the Avatar online data
#### library ####
library(tidyverse)
library(brms)
library(tidybayes)
#### Source ####
# gets data files and functions
source("ProcessData/ProcessData.R")
#### Functions ####
squash <- function(y, max, min, squash){
y <- y * ((max-squash) - (min + squash)) + (min + squash)
}
source("Functions/0_getLegend.R")
#### Processing ####
# filter out "bad" participants
df_avatar <- df_avatar %>%
filter(exclude == FALSE)
pre_remove <- nrow(df_avatar)
model_data <- df_avatar %>%
filter(abs_norm_place <= 1.1) %>%
mutate(abs_norm_place = ifelse(abs_norm_place > 1, 1, abs_norm_place),
abs_norm_place = squash(abs_norm_place, 1, 0, 1e-4),
norm_delta = Decision_Delta/max(Decision_Delta))
post_remove <- nrow(model_data)
data_loss <- 100 - ((post_remove/pre_remove)*100)
print(paste("data lost = ", round(data_loss, digits = 2), "%", sep =""))
# save
save(model_data, file = "scratch/model_data")
# tidy
rm(post_remove, pre_remove)
setwd("E:/Github/Avatar_online")
#### Modelling ####
# Modelling the Avatar online data
#### library ####
library(tidyverse)
library(brms)
library(tidybayes)
#### Source ####
# gets data files and functions
source("ProcessData/ProcessData.R")
#### Functions ####
squash <- function(y, max, min, squash){
y <- y * ((max-squash) - (min + squash)) + (min + squash)
}
source("Functions/0_getLegend.R")
#### Processing ####
# filter out "bad" participants
df_avatar <- df_avatar %>%
filter(exclude == FALSE)
pre_remove <- nrow(df_avatar)
model_data <- df_avatar %>%
filter(abs_norm_place <= 1.1) %>%
mutate(abs_norm_place = ifelse(abs_norm_place > 1, 1, abs_norm_place),
abs_norm_place = squash(abs_norm_place, 1, 0, 1e-4),
norm_delta = Decision_Delta/max(Decision_Delta))
post_remove <- nrow(model_data)
data_loss <- 100 - ((post_remove/pre_remove)*100)
print(paste("data lost = ", round(data_loss, digits = 2), "%", sep =""))
# save
save(model_data, file = "scratch/model_data")
# tidy
rm(post_remove, pre_remove)
m_iter <- 2000
m_control <- list(adapt_delta = .95)
m_priors <- c(set_prior("student_t(3, -1.41, 1)",
class = "Intercept"),
set_prior("student_t(3, 0, 1)",
class = "b",
coef = "ConditionAutomatic"),
set_prior("student_t(3, 0, 1)",
class = "b",
coef = "ConditionAutomatic:dist_typeFar"),
set_prior("student_t(3, 1.55, 1)",
class = "b",
coef = "dist_typeFar"))
m3 <- brm(abs_norm_place ~ Condition * dist_type + (Condition * dist_type|participant),
prior = m_priors,
data = model_data,
family = "beta",
chains = 1,
iter = m_iter,
warmup = m_iter/2,
sample_prior = "only",
control = m_control)
summary(m3)
m_iter <- 2000
m_control <- list(adapt_delta = .99)
m3 <- brm(abs_norm_place ~ Condition * dist_type + (Condition * dist_type|participant),
prior = m_priors,
data = model_data,
family = "beta",
chains = 1,
iter = m_iter,
warmup = m_iter/2,
sample_prior = "only",
control = m_control)
summary(m3)
m_iter <- 2500
m_control <- list(adapt_delta = .99)
m3 <- brm(abs_norm_place ~ Condition * dist_type + (Condition * dist_type|participant),
prior = m_priors,
data = model_data,
family = "beta",
chains = 1,
iter = m_iter,
warmup = m_iter/2,
sample_prior = "only",
control = m_control)
m_iter/1.5
m_iter/2
m_iter <- 2000
m_iter/2
m_iter/1.5
m_iter/4
# parameters for all models
m_iter <- 2000
m_control <- list(adapt_delta = .99)
m3 <- brm(abs_norm_place ~ Condition * dist_type + (Condition * dist_type|participant),
prior = m_priors,
data = model_data,
family = "beta",
chains = 1,
iter = m_iter,
warmup = m_iter/2 + m_iter/4,
sample_prior = "only",
control = m_control)
summary(m3)
.3 * m_iter
.5 * m_iter
. * m_iter
.75 * m_iter
m_iter/2 + m_iter/4
#### > > Run priors only version ####
m3 <- brm(abs_norm_place ~ Condition * dist_type + (Condition * dist_type|participant),
prior = m_priors,
data = model_data,
family = "beta",
chains = 1,
iter = m_iter,
warmup = m_iter,
sample_prior = "only",
control = m_control)
4000 * .75
m_iter <- 4000
m3 <- brm(abs_norm_place ~ Condition * dist_type + (Condition * dist_type|participant),
prior = m_priors,
data = model_data,
family = "beta",
chains = 1,
iter = m_iter,
warmup = m_iter*.75,
sample_prior = "only",
control = m_control)
summary(m3)
x11()
plot(marginal_effects(m3))
m1_nopriors <- brm(abs_norm_place ~ Condition * dist_type + (Condition * dist_type|participant),
data = model_data,
family = "beta",
chains = 1,
iter = m_iter,
warmup = m_iter/2,
control = m_control)
beep()
summary(m1_nopriors)
# save
save(m1_nopriors, file = "ModelOutput/m_noPriors")
m_priors <- c(set_prior("student_t(3, -1.41, 1)",
class = "Intercept"),
set_prior("student_t(3, 0, 1)",
class = "b",
coef = "ConditionAutomatic"),
set_prior("student_t(3, 0, 1)",
class = "b",
coef = "ConditionAutomatic:dist_typeFar"),
set_prior("student_t(3, 1.55, 1)",
class = "b",
coef = "dist_typeFar"))
# model
m1_withpriors <- brm(abs_norm_place ~ Condition * dist_type + (Condition * dist_type|participant),
prior = m_priors,
data = model_data,
family = "beta",
chains = 1,
iter = m_iter,
warmup = m_iter/2,
control = m_control)
beep()
save(m1_withpriors, file = "ModelOutput/m_withPriors")
save(m1_withpriors, file = "ModelOutput/m_withPriors")
